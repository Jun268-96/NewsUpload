import streamlit as st
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import uuid
from urllib.parse import urljoin
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json

# --- 1. í”„ë¡œì íŠ¸ ê°œìš” & 6. í™”ë©´ êµ¬ì„± ---
st.set_page_config(layout="wide", page_title="EduNews Board")
st.title("ğŸ‘¨â€ğŸ« EduNews Board")
st.caption("ì´ˆë“±í•™êµ ê³ í•™ë…„ ëŒ€ìƒ êµì‹¤ìš© ë‰´ìŠ¤ íë ˆì´ì…˜ í”Œë«í¼")

# --- ìƒìˆ˜ ì •ì˜ ---
CATEGORIES = {
    "ì‚¬íšŒ": "blue",
    "ê³¼í•™": "green",
    "ê¸°ìˆ ": "orange",
    "ìƒí™œ/ë¬¸í™”": "violet",
    "ì„¸ê³„": "red"
}
# Google Sheetì˜ í—¤ë”ì™€ ìˆœì„œê°€ ì¼ì¹˜í•´ì•¼ í•¨
SHEET_HEADERS = ['id', 'url', 'title', 'image_url', 'category', 'added_date']

# --- gspreadë¥¼ ì‚¬ìš©í•œ Google Sheets ì—°ê²° í•¨ìˆ˜ ---
@st.cache_resource(ttl=600)  # 10ë¶„ ë™ì•ˆ ì—°ê²° ìºì‹œ
def connect_to_gsheet():
    try:
        creds_json_str = st.secrets["gcp_service_account"]["json_credentials"]
        creds_dict = json.loads(creds_json_str)
        
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        
        # 'EduNewsDB'ëŠ” ì‹¤ì œ Google Sheet íŒŒì¼ ì´ë¦„ì…ë‹ˆë‹¤.
        spreadsheet = client.open("EduNewsDB") 
        worksheet = spreadsheet.worksheet("Sheet1") # 'Sheet1'ì€ ì‹œíŠ¸ ì´ë¦„ì…ë‹ˆë‹¤.
        return worksheet
    except Exception as e:
        st.error(f"Google Sheetsì— ì—°ê²°í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

worksheet = connect_to_gsheet()

# --- ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def fetch_metadata(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        title = soup.find('meta', property='og:title')
        image_url = soup.find('meta', property='og:image')
        title = title['content'] if title else soup.title.string
        if image_url:
            image_url = urljoin(url, image_url['content'])
        return {"title": title.strip() if title else "ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "image_url": image_url, "success": True}
    except Exception:
        return {"success": False}

# --- ë‰´ìŠ¤ ë“±ë¡ í¼ ---
with st.expander("ğŸ“° ìƒˆ ë‰´ìŠ¤ ì¶”ê°€í•˜ê¸°"):
    with st.form("new_news_form", clear_on_submit=True):
        news_url = st.text_input("ë‰´ìŠ¤ ê¸°ì‚¬ URLì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="https://example.com/news/123")
        news_category = st.selectbox("ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=list(CATEGORIES.keys()))
        submitted = st.form_submit_button("ë“±ë¡í•˜ê¸°")

        if submitted and news_url and worksheet:
            with st.spinner("ë‰´ìŠ¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                metadata = fetch_metadata(news_url)

            if metadata["success"]:
                new_article_data = {
                    "id": str(uuid.uuid4()),
                    "url": news_url,
                    "title": metadata["title"],
                    "image_url": metadata["image_url"] or "", # ì´ë¯¸ì§€ê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì €ì¥
                    "category": news_category,
                    "added_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                # í—¤ë” ìˆœì„œì— ë§ê²Œ ê°’ ë¦¬ìŠ¤íŠ¸ ìƒì„±
                row_to_add = [new_article_data.get(h, "") for h in SHEET_HEADERS]
                worksheet.append_row(row_to_add, value_input_option='USER_ENTERED')
                
                st.success(f"'{metadata['title']}' ë‰´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡í–ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("ë‰´ìŠ¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# --- ë‰´ìŠ¤ ëª©ë¡ í‘œì‹œ ---
if worksheet:
    # Google Sheetì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    all_data = worksheet.get_all_records()
    if not all_data:
        st.info("ì•„ì§ ë“±ë¡ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. 'ìƒˆ ë‰´ìŠ¤ ì¶”ê°€í•˜ê¸°'ë¥¼ í†µí•´ ë‰´ìŠ¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
    else:
        news_list = pd.DataFrame(all_data)

        for category, color in CATEGORIES.items():
            st.markdown(f"---")
            st.subheader(f":{color}[{category}]")

            # Pandas DataFrameìœ¼ë¡œ í•„í„°ë§ ë° ì •ë ¬
            category_df = news_list[news_list['category'] == category]
            
            # added_dateë¥¼ datetimeìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì •ë ¬ (ì˜¤ë¥˜ ë°©ì§€)
            category_df['added_date_dt'] = pd.to_datetime(category_df['added_date'], errors='coerce')
            sorted_df = category_df.sort_values(by='added_date_dt', ascending=False)

            if sorted_df.empty:
                st.write("ì´ ì£¼ì œì˜ ë‰´ìŠ¤ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
                continue

            cols = st.columns(3)
            # DataFrameì˜ í–‰ì„ ìˆœíšŒí•˜ë©° ë‰´ìŠ¤ ì¹´ë“œ ìƒì„±
            for i, news_row in enumerate(sorted_df.itertuples()):
                col = cols[i % 3]
                with col:
                    with st.container(border=True):
                        if pd.notna(news_row.image_url) and news_row.image_url:
                            st.image(news_row.image_url)
                        else:
                            st.markdown(f"<p style='text-align: center; color: grey; padding: 20px 0;'>ì´ë¯¸ì§€ ì—†ìŒ</p>", unsafe_allow_html=True)
                        
                        st.markdown(f"##### [{str(news_row.title)}]({str(news_row.url)})")
                        
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.caption(f"ë“±ë¡: {str(news_row.added_date)}")
                        with col2:
                            if st.button("ì‚­ì œ", key=f"del_{news_row.id}", type="secondary", use_container_width=True):
                                try:
                                    # gspreadëŠ” í–‰ ë²ˆí˜¸ë¡œ ì‚­ì œí•˜ë¯€ë¡œ, id ê°’ìœ¼ë¡œ í•´ë‹¹ ì…€ì„ ì°¾ì•„ í–‰ ë²ˆí˜¸ë¥¼ ì•Œì•„ë‚´ì•¼ í•¨
                                    cell = worksheet.find(news_row.id)
                                    if cell:
                                        worksheet.delete_rows(cell.row)
                                        st.success("ë‰´ìŠ¤ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
                                        st.rerun()
                                    else:
                                        st.error("ì‚­ì œí•  ë‰´ìŠ¤ë¥¼ ì‹œíŠ¸ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                                except gspread.exceptions.CellNotFound:
                                    st.error("ì‚­ì œí•  ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ ì‚­ì œë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                except Exception as e:
                                    st.error(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

else:
    st.warning("Google Sheetsì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ì•±ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")